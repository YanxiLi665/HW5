{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1d99f9",
   "metadata": {},
   "source": [
    "### 1. The \"first pre-lecture video\" (above) describes hypothesis testing as addressing \"an idea that can be tested\", and the end of the video then discusses what our actual intended purpose in setting up a null hypothesis is. What is the key factor that makes the difference between ideas that can, and cannot be examined and tested statistically?  What would you describe is the key \"criteria\" defining what a good null hypothesis is? And what is the difference between a null hypothesis and an alternative hypothesis in the context of hypothesis testing? Answer these questions with concise explanations in your own words.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4d84c",
   "metadata": {},
   "source": [
    "The key factor that distinguishes ideas that can be tested statistically from those that cannot is falsifiability. A hypothesis must be structured in a way that allows it to be tested and potentially proven wrong through evidence.\n",
    "\n",
    "Key Criteria for a Good Null Hypothesis:\n",
    "\n",
    "1. Testability: It must be possible to gather data that can confirm or reject the hypothesis.\n",
    "\n",
    "2. Specificity: It should clearly state the expected outcome, often suggesting no effect or no difference.\n",
    "\n",
    "3. Simplicity: A good null hypothesis is straightforward and easy to understand.\n",
    "\n",
    "4. Neutrality: It should serve as a statement of no effect or status quo, providing a basis for comparison with the alternative hypothesis.\n",
    "\n",
    "Difference Between Null and Alternative Hypothesis:\n",
    "\n",
    "1. Null Hypothesis (H₀): This posits that there is no effect or difference. It serves as the default position that indicates no relationship between variables.\n",
    "\n",
    "2. Alternative Hypothesis (H₁): This proposes that there is an effect or a difference. It represents what researchers aim to support with evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd63361",
   "metadata": {},
   "source": [
    "### 2. Towards the end of the \"first pre-lecture\" video (above) it is stated that, \"It is important to note that outcomes of tests refer to the population parameter, rather than the sample statistic! As such, the result that we get is for the population.\" In terms of the distinctions between the concepts of $x_i\\!$'s, $\\bar x$, $\\mu$, and $\\mu_0$, how would you describe what the sentence above means? Explain this concisely in your own words for a \"non-statsitical\" audience, defining the technical statistical terminology you use in your answer.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0fb6c2",
   "metadata": {},
   "source": [
    "The sentence highlights that when we perform a statistical test, we’re drawing conclusions about the entire population, not just the sample we gathered data from. Here’s a breakdown of the terms in simpler language:\n",
    "\n",
    "- $x_i\\!$: These are the individual data points collected in a study, such as the heights of various people.\n",
    "- $\\bar x$: This represents the *average* of the data points in our sample, like the average height of the individuals we measured.\n",
    "- $\\mu$: This denotes the true average (mean) of the entire population, which we cannot measure directly. For instance, it could be the average height of *all* people in a country.\n",
    "- $\\mu_0$: This is the specific value we are testing in our hypothesis regarding the population mean, like suggesting that the average height of all people in a country is 170 cm.\n",
    "\n",
    "The main point is that, while we use our sample’s average ($\\bar x$) to conduct tests, the outcomes of those tests aim to make inferences about the true average of the population ($\\mu$), not just our sample. Therefore, the conclusions we draw apply to the entire population, not just the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e669c0ba",
   "metadata": {},
   "source": [
    "### 3. The second \"Pre-lecture\" video (above) explains that we \"imagine a world where the null hypothesis is true\" when calculating a p-value? Explain why this is in your own words in a way that makes the most sense to you.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd10e05",
   "metadata": {},
   "source": [
    "When we calculate a p-value, we start by assuming that the null hypothesis is true—essentially, we envision a scenario where there is no effect or difference, as the null hypothesis suggests. This assumption helps us predict the kind of data or results we would expect if it were correct.\n",
    "\n",
    "Next, we compare our actual sample results to this hypothetical scenario. If our observed data significantly differs from what we would anticipate under the null hypothesis, it indicates that the null may not be valid. The p-value quantifies this difference; a smaller p-value indicates that our observed result is less likely to occur in that imagined scenario, making us more inclined to reject the null hypothesis. Thus, assuming the null is true serves as a baseline for assessing how surprising or typical our data is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b225dc",
   "metadata": {},
   "source": [
    "### 4. The second \"Pre-lecture\" video (above) suggests that a smaller p-value makes the null hypothesis look more ridiculous. Explain why this is in your own words in a way that makes the most sense to you, clarifying the meaning of any technical statistical terminology you use in your answer.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645a81a",
   "metadata": {},
   "source": [
    "The notion that a smaller p-value makes the null hypothesis seem more \"ridiculous\" suggests that, if we assume the null hypothesis is true, the data we observe is highly unlikely.\n",
    "\n",
    "A p-value represents the probability of obtaining results as extreme as (or more extreme than) those in our sample, *given* that the null hypothesis holds true. When this p-value is very small, it indicates that the chances of observing our data under the null hypothesis are low. Therefore, if the null hypothesis were accurate, encountering such extreme results would be quite unexpected.\n",
    "\n",
    "This element of \"surprise\" contributes to the perception that the null hypothesis is less credible or more \"ridiculous\"—the data does not fit well within the framework where the null is true, implying that our assumption may be incorrect. Consequently, we are more likely to reject the null hypothesis in favor of the alternative, which may provide a better explanation for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83340240",
   "metadata": {},
   "source": [
    "### 5. Güntürkün (2003) recorded how kissing couples tilt their heads. 80 out of 124 couples, or 64.5% tilted their heads to the right. Simulate a **p-value** using a \"50/50 coin-flipping\" model for the assumption of the **null hypothesis** $H_0$ that the population of humans don't have left or right head tilt tendencies when kissing, and use the table below to determine the level of evidence we have against $H_0$. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4500786a",
   "metadata": {},
   "source": [
    "Simulation Steps：\n",
    "\n",
    "1. Set up the null hypothesis ($H_0$): There is no preference in head tilt direction, meaning each kiss has a 50% chance of being a right tilt.\n",
    "2. Simulate 10,000 trials: For each trial, simulate 124 \"coin flips\" (each representing a couple's head tilt). Count how many times the \"coin\" lands on \"right\".\n",
    "3. Calculate the p-value: The p-value is the proportion of trials where the number of \"right\" head tilts is as extreme or more extreme than the observed 80 out of 124 couples.\n",
    " \n",
    "Here's an example of simulation code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b486e4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters for the simulation\n",
    "n_trials = 10000\n",
    "n_couples = 124\n",
    "observed_right_tilts = 80\n",
    "\n",
    "# Simulate trials assuming a 50/50 chance for right/left tilts\n",
    "simulated_right_tilts = np.random.binomial(n=n_couples, p=0.5, size=n_trials)\n",
    "\n",
    "# Calculate the p-value: proportion of trials where right tilts >= observed right tilts\n",
    "p_value = np.mean(simulated_right_tilts >= observed_right_tilts)\n",
    "p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d68a9f",
   "metadata": {},
   "source": [
    "Since 0.001 ≥ p, this result provides very strong evidence against the null hypothesis ($H_0$). This means it is very unlikely that the observed head tilt pattern (80 out of 124 couples tilting right) would occur if there truly were no preference between right or left tilting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f91662",
   "metadata": {},
   "source": [
    "### 6. Can a smaller p-value definitively prove that the null hypothesis is false? Is it possible to definitively prove that Fido (from the \"second pre-lecture video\") is innocent using a p-value? Is it possible to difinitively prove that Fido is guilty using a p-value? How low or high does a p-value have to be to definitely prove one or the other? Explain this concisely in your own words.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856f0421",
   "metadata": {},
   "source": [
    "1. **Can a smaller p-value prove the null hypothesis is false?**  \n",
    "No, a smaller p-value suggests evidence against the null hypothesis, but it does not prove it is false. Random variation could still explain the data.\n",
    "\n",
    "2. **Can we prove Fido is innocent with a p-value?**  \n",
    "No, a p-value cannot prove innocence. A large p-value suggests insufficient evidence to reject the idea that Fido is innocent, but it doesn't confirm it.\n",
    "\n",
    "3. **Can we prove Fido is guilty with a p-value?**  \n",
    "No, a p-value can suggest strong evidence against the null hypothesis (Fido’s innocence) but cannot definitively prove guilt.\n",
    "\n",
    "4. **How low or high does a p-value have to be to prove something?**  \n",
    "A p-value cannot provide absolute proof, regardless of its size. It only indicates probability—low p-values suggest strong evidence against the null, while high p-values indicate insufficient evidence to reject it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9cff3d",
   "metadata": {},
   "source": [
    "### 7. In the second half of the \"first pre-lecture video\" the concept of a \"one sided\" (or \"one tailed\") test is introduced in contrast to a \"two sided\" (or \"two tailed\") test. Work with a ChatBot to adjust the code from \"Demo II of  the Week 5 TUT\" (which revisits the \"Vaccine Data Analysis Assignment\" from Week 04 HW \"Question 8\") in order to compute a p-value for a \"one sided\" (or \"one tailed\") hypothesis test rather than the \"two sided\" (or \"two tailed\") version it provides. Describe (perhaps with the help of your ChatBot) what changed in the code; how this changes the interpretation of the hypothesis test; and whether or not we should indeed expect the p-value to be smaller in the \"one tailed\" versus \"two tailed\" analysis. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9807fff6",
   "metadata": {},
   "source": [
    "After adjust the code, we can changes the interpretation:\n",
    "- Two-Sided Test: A two-sided test checks for differences in both directions—whether the mean difference is either greater than or less than zero. It is useful when we are interested in detecting any difference between the initial and final health scores, without assuming a direction in advance.\n",
    "\n",
    "- One-Sided Test: A one-sided test, on the other hand, focuses on testing for a difference in one specific direction—for example, testing if the final health scores are specifically higher than the initial scores. This is relevant if we have a clear expectation about the direction of the effect (e.g., expecting health scores to improve after vaccination).\n",
    "\n",
    "Our expextation of P-value Size:\n",
    "- One-Sided vs. Two-Sided P-value: The p-value from a one-sided test is usually smaller than that of a two-sided test, assuming the data supports the direction of the alternative hypothesis. This is because the one-sided test focuses all its probability on one direction, making it easier to find significance if the observed effect is in the expected direction.\n",
    "\n",
    "- For example, if the original two-tailed p-value is 0.04, then the one-tailed p-value (if the t-statistic is positive) would be 0.02, suggesting stronger evidence for rejecting the null hypothesis when we only care about one direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c1c5ae",
   "metadata": {},
   "source": [
    "### 8. Complete the following assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da01be92",
   "metadata": {},
   "source": [
    "**Problem Introduction**\n",
    "\n",
    "The original Fisher tea experiment, a famous piece of statistical history, was conducted by Ronald Fisher in the 1920s. It involved his colleague, Dr. Muriel Bristol, who claimed she could distinguish whether milk or tea was poured first into her cup. Fisher, skeptical of her claim, proposed a statistical hypothesis test to evaluate whether her ability was due to chance. In the test, Dr. Bristol was given 8 cups of tea—4 with milk poured first and 4 with tea poured first—without knowing which was which, and she successfully identified the order for all cups.\n",
    "\n",
    "This project attempts to recreate a similar experiment using a random sample of 80 students from STA130. Each student was given a cup of tea and asked to identify whether the milk or the tea was poured first. In this sample, 49 students correctly identified the order of pouring. The goal of this analysis is to determine whether the ability of these students to identify the pouring order is purely due to random guessing or if there is evidence to suggest a genuine ability to distinguish between the two.\n",
    "\n",
    "\n",
    "**Statements of the Null and Alternative Hypotheses**\n",
    "\n",
    "**Null Hypothesis (H₀):**\n",
    "\n",
    "**Formal**: The probability p that a student correctly identifies the pouring order is 0.5. This suggests that students are simply guessing.\n",
    "\n",
    "**Informal**: \"STA130 students are guessing when they identify whether tea or milk was poured first, with no actual ability to distinguish between the two.\"\n",
    "\n",
    "**Alternative Hypothesis (Hₐ)**: \n",
    "\n",
    "p ≠ 0.5, indicating that the ability of the students to identify the pouring order is not just due to random guessing.\n",
    "\n",
    "**Quantitative Analysis**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b3c8461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0124611797498115,\n",
       " 0.044171344908442434,\n",
       " (0.5057440726485105, 0.7192559273514896))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Sample information\n",
    "n = 80\n",
    "x = 49  # number of correct identifications\n",
    "p_hat = x / n\n",
    "p_0 = 0.5\n",
    "\n",
    "# Z-test for one proportion\n",
    "z = (p_hat - p_0) / np.sqrt((p_0 * (1 - p_0)) / n)\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z)))  # Two-tailed test\n",
    "\n",
    "# 95% Confidence Interval\n",
    "z_star = stats.norm.ppf(0.975)\n",
    "margin_of_error = z_star * np.sqrt((p_hat * (1 - p_hat)) / n)\n",
    "conf_interval = (p_hat - margin_of_error, p_hat + margin_of_error)\n",
    "\n",
    "z, p_value, conf_interval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63705392",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "We use the z-test to compare the observed proportion p to the hypothesized value P₀.\n",
    "The p-value helps determine the probability of observing 49 or more correct identifications out of 80 if students are merely guessing.\n",
    "The confidence interval provides a range of plausible values for the proportion of students who can correctly identify the pouring order, allowing us to assess if 0.5 is a likely value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18676b3b",
   "metadata": {},
   "source": [
    "**Findings and Discussion**\n",
    "\n",
    "Interpretation of p-value: If the p-value is less than the significance level (e.g.0.05), we reject the null hypothesis, suggesting that there is evidence against the assumption that students are merely guessing.\n",
    "Confidence Interval Interpretation: If the 95% confidence interval for p does not include 0.5, it suggests that the true proportion of students who can identify the pouring order differs from 0.5, further supporting the conclusion that students are not just guessing.\n",
    "\n",
    "**Conclusion regarding the Null Hypothesis**\n",
    "\n",
    "Based on the results of the z-test and the confidence interval, we conclude whether or not there is sufficient evidence to reject the null hypothesis $H_0$. If we reject $H_0$, it suggests that STA130 students possess some ability to distinguish between the pouring orders of tea and milk, beyond what would be expected by random guessing. Otherwise, if we fail to reject $H_0$, it suggests that the students' performance could be attributed to chance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df65a4",
   "metadata": {},
   "source": [
    "### 9. Have you reviewed the course wiki-textbook and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3f9e73",
   "metadata": {},
   "source": [
    "Yes sir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a81fd56",
   "metadata": {},
   "source": [
    "Here’s a **summary** of our discussion on adjusting the code for a one-sided hypothesis test and the related concepts:\n",
    "\n",
    "Original Context:\n",
    "\n",
    "We started with the code from \"Demo II of the Week 5 TUT,\" which involves analyzing a dataset of patients' initial and final health scores to evaluate a vaccine's effectiveness.\n",
    "The original code performed a paired t-test using a two-sided (or two-tailed) test, comparing the initial and final health scores to see if there was any significant difference.\n",
    "Adjusting the Code for a One-Sided Test:\n",
    "\n",
    "To shift from a two-sided to a one-sided test, we modified how the p-value is calculated:\n",
    "Compute the t-statistic and two-tailed p-value using stats.ttest_rel.\n",
    "Adjust the p-value for a one-sided test by halving it if the t-statistic is positive (indicating an increase in health scores).\n",
    "If the t-statistic is negative, calculate the one-sided p-value as \n",
    "1\n",
    "−\n",
    "(half of the two-tailed p-value)\n",
    "1−(half of the two-tailed p-value).\n",
    "Interpretation of Changes:\n",
    "\n",
    "Two-Sided Test: Tests for differences in both directions (greater or less than zero). It’s suitable when no prior assumption about the direction of the change is made.\n",
    "One-Sided Test: Focuses on testing for a difference in one specific direction (e.g., whether final health scores are higher than initial scores). This is used when we expect a specific directional outcome.\n",
    "Expectations on P-value:\n",
    "\n",
    "A one-sided p-value is usually smaller than a two-sided p-value if the data supports the direction of the hypothesis. This happens because the one-sided test focuses only on one direction, making it easier to detect significance in that direction.\n",
    "A smaller p-value in a one-sided test indicates stronger evidence against the null hypothesis in the specified direction, but it sacrifices the ability to detect an effect in the opposite direction.\n",
    "Conclusion:\n",
    "\n",
    "By moving to a one-sided test, we are refining our focus to detect changes in a specific direction, which can lead to a lower p-value if the observed data aligns with our expectations. However, using a one-sided test is only appropriate when there is a justified expectation for a particular direction of change.\n",
    "\n",
    "https://chatgpt.com/share/670f2be6-0c4c-8004-a3f4-15797dba3f00  chat log histories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
